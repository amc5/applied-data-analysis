---
title: "Module 09"
output:
    github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	comment = "##",
	prompt = TRUE,
	tidy = TRUE,
	tidy.opts = list(width.cutoff = 75),
	fig.path = "img/"
)
```
# Statistical Inference - Hypothesis Testing



## Review of Common Distributions

Here are a couple of important things to remember...

### Discrete Random Variables

| Name           | Notation                | PMF $f(x)$ = $P(X=x)$                      | $\mu$ = $E(X)$     | $\sigma^2$ = *Var* $(X)$       |                          |
|:-------------- |:----------------------- |:------------------------------------------ |:------------------ |:------------------------------ |:-----------------------  |
| Bernoulli      | $X$ ~ *BERN*$(p)$       | $f(x)$ = $p^x(1-p)^{1-x}$                  | *p*                | *p(1-p)*                       | x = {0,1}                |
| Binomial       | $X$ ~ *BIN*$(n, p)$     | <img src="img/binom-1.svg" width="220px"/> | *np*               | *np(1-p)*                      | x = {0,1,..., k}         |
| Poisson        | $X$ ~ *POIS*$(\lambda)$ | <img src="img/poisson.svg" width="175px"/> | $\lambda$          | $\lambda$                      | x = {0,1,..., +$\infty$} |

### Continuous Random Variables

| Name         | Notation                      | PDF $f_X(x)$                                 | $\mu$ = $E(X)$     | $\sigma^2$ = *Var* $(X)$ |
|:------------ |:----------------------------- | -------------------------------------------- |:------------------ |:------------------- |:---------------------- |
| Beta         | $X$ ~ *BETA*$(\alpha,\beta)$  | $f(x)$ = $K$ $x^{\alpha-1}(1-x)^{\beta-1}$   |                    |                     |                        |
| Uniform      | $X$ ~ *U*$(a,b)$              | <img src="img/uni-1.svg" width="110px"/>     | <img src="img/uni-2.svg" width="100px"/> | <img src="img/uni-3.svg" width="115px"/> |                        |
| Normal      | $X$ ~ *N*$(\mu,\sigma^2)$      |                                              |                    |                     |                        |
| Exponential |
| Student's t | 










Coefficient of Variation = ratio of the standard deviation to the mean

v <- rnorm(100, mean=5, sd=2)
CV <- sd(v)/mean(v)



Roughly, the central limit theorem states that the distribution of the sum (or average) of a large number of independent, identically distributed variables will be approximately normal, regardless of the underlying distribution.


The central limit theorem states that averages of random variables independently drawn from independent distributions converge in distribution to the normal, that is, become normally distributed when the number of random variables is sufficiently large. Also, variables that are expected to be the sum of many independent processes (such as measurement errors) often have distributions that are nearly normal.
